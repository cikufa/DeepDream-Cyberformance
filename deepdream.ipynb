{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cikufa/DeepDream-Cyberformance/blob/main/deepdream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNFpKfEwF3mO",
        "outputId": "1fa5b910-678b-412a-d332-06bc3f1aece7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
        "img_path = 'gdrive/MyDrive/DeepDream/deepDreamData'\n",
        "\n",
        "timg = 'gdrive/MyDrive/DeepDream/frame1.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QzURbGaIKIt"
      },
      "outputs": [],
      "source": [
        "# Download an image and read it into a NumPy array.\n",
        "# def download(url, max_dim=None):\n",
        "#   name = url.split('/')[-1]\n",
        "#   image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "#   img = PIL.Image.open(image_path)\n",
        "#   if max_dim:\n",
        "#     img.thumbnail((max_dim, max_dim))\n",
        "#   return np.array(img)\n",
        "\n",
        "def preprocess(img, max_dim= None):\n",
        "  with Image.open(img) as img:\n",
        "    img = img.resize((1920//4, 1080//4),\n",
        "                          Image.ANTIALIAS )\n",
        "  \n",
        "  # if max_dim:\n",
        "  #   img.thumbnail((max_dim, max_dim))\n",
        "  return np.array(img)\n",
        "\n",
        "# Normalize an image\n",
        "def deprocess(img):\n",
        "  img = 255*(img + 1.0)/2.0\n",
        "  return tf.cast(img, tf.uint8)\n",
        "\n",
        "# Display an image\n",
        "def show(img):\n",
        "  display.display(Image.fromarray(np.array(img)))\n",
        "\n",
        "# Downsizing the image makes it easier to work with.\n",
        "#original_img = download(url, max_dim=500)\n",
        "#original_img = preprocess(img)\n",
        "#show(original_img)\n",
        "#display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTb6I_zKIuqU"
      },
      "outputs": [],
      "source": [
        "def calc_loss(img, model):\n",
        "  # Pass forward the image through the model to retrieve the activations.\n",
        "  # Converts the image into a batch of size 1.\n",
        "  img_batch = tf.expand_dims(img, axis=0)\n",
        "  layer_activations = model(img_batch)\n",
        "  if len(layer_activations) == 1:\n",
        "    layer_activations = [layer_activations]\n",
        "\n",
        "  losses = []\n",
        "  for act in layer_activations:\n",
        "    loss = tf.math.reduce_mean(act)\n",
        "    losses.append(loss)\n",
        "\n",
        "  return  tf.reduce_sum(losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN5hAkaeIxdp"
      },
      "outputs": [],
      "source": [
        "class DeepDream(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "      input_signature=(\n",
        "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
        "  )\n",
        "  def __call__(self, img, steps, step_size):\n",
        "      print(\"Tracing\")\n",
        "      loss = tf.constant(0.0)\n",
        "      for n in tf.range(steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "          # This needs gradients relative to `img`\n",
        "          # `GradientTape` only watches `tf.Variable`s by default\n",
        "          tape.watch(img)\n",
        "          loss = calc_loss(img, self.model)\n",
        "\n",
        "        # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
        "        gradients = tape.gradient(loss, img)\n",
        "\n",
        "        # Normalize the gradients.\n",
        "        gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "\n",
        "        # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
        "        # You can update the image by directly adding the gradients (because they're the same shape!)\n",
        "        img = img + gradients*step_size\n",
        "        img = tf.clip_by_value(img, -1, 1)\n",
        "\n",
        "      return loss, img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaxLmoRlI1XM"
      },
      "outputs": [],
      "source": [
        "# def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
        "#   # Convert from uint8 to the range expected by the model.\n",
        "#   img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "#   img = tf.convert_to_tensor(img)\n",
        "#   step_size = tf.convert_to_tensor(step_size)\n",
        "#   steps_remaining = steps\n",
        "#   step = 0\n",
        "#   while steps_remaining:\n",
        "#     if steps_remaining>100:\n",
        "#       run_steps = tf.constant(100)\n",
        "#     else:\n",
        "#       run_steps = tf.constant(steps_remaining)\n",
        "#     steps_remaining -= run_steps\n",
        "#     step += run_steps\n",
        "\n",
        "#     loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
        "\n",
        "#     display.clear_output(wait=True)\n",
        "#     show(deprocess(img))\n",
        "#     print (\"Step {}, loss {}\".format(step, loss))\n",
        "\n",
        "\n",
        "#   result = deprocess(img)\n",
        "#   display.clear_output(wait=True)\n",
        "#   show(result)\n",
        "\n",
        "#   return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BkDZRkmI-Y2"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "# start = time.time()\n",
        "\n",
        "# OCTAVE_SCALE = 1.30\n",
        "\n",
        "# img = tf.constant(np.array(original_img))\n",
        "# base_shape = tf.shape(img)[:-1]\n",
        "# float_base_shape = tf.cast(base_shape, tf.float32)\n",
        "\n",
        "# #for n in range(-2, 3):\n",
        "# for n in range(2):\n",
        "#   new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n",
        "\n",
        "#   img = tf.image.resize(img, new_shape).numpy()\n",
        "\n",
        "#   img = run_deep_dream_simple(img=img, steps=50, step_size=0.01)\n",
        "\n",
        "# display.clear_output(wait=True)\n",
        "# img = tf.image.resize(img, base_shape)\n",
        "# img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
        "# #show(img)\n",
        "\n",
        "# end = time.time()\n",
        "# end-start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZJaqA2ZJBcK"
      },
      "outputs": [],
      "source": [
        "def random_roll(img, maxroll):\n",
        "  # Randomly shift the image to avoid tiled boundaries.\n",
        "  shift = tf.random.uniform(shape=[2], minval=-maxroll, maxval=maxroll, dtype=tf.int32)\n",
        "  img_rolled = tf.roll(img, shift=shift, axis=[0,1])\n",
        "  return shift, img_rolled\n",
        "\n",
        "\n",
        "class TiledGradients(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "      input_signature=(\n",
        "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=[2], dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.int32),)\n",
        "  )\n",
        "  def __call__(self, img, img_size, tile_size=512):\n",
        "    shift, img_rolled = random_roll(img, tile_size)\n",
        "\n",
        "    # Initialize the image gradients to zero.\n",
        "    gradients = tf.zeros_like(img_rolled)\n",
        "\n",
        "    # Skip the last tile, unless there's only one tile.\n",
        "    xs = tf.range(0, img_size[1], tile_size)[:-1]\n",
        "    if not tf.cast(len(xs), bool):\n",
        "      xs = tf.constant([0])\n",
        "    ys = tf.range(0, img_size[0], tile_size)[:-1]\n",
        "    if not tf.cast(len(ys), bool):\n",
        "      ys = tf.constant([0])\n",
        "\n",
        "    for x in xs:\n",
        "      for y in ys:\n",
        "        # Calculate the gradients for this tile.\n",
        "        with tf.GradientTape() as tape:\n",
        "          # This needs gradients relative to `img_rolled`.\n",
        "          # `GradientTape` only watches `tf.Variable`s by default.\n",
        "          tape.watch(img_rolled)\n",
        "\n",
        "          # Extract a tile out of the image.\n",
        "          img_tile = img_rolled[y:y+tile_size, x:x+tile_size]\n",
        "          loss = calc_loss(img_tile, self.model)\n",
        "\n",
        "        # Update the image gradients for this tile.\n",
        "        gradients = gradients + tape.gradient(loss, img_rolled)\n",
        "\n",
        "    # Undo the random shift applied to the image and its gradients.\n",
        "    gradients = tf.roll(gradients, shift=-shift, axis=[0,1])\n",
        "\n",
        "    # Normalize the gradients.\n",
        "    gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "\n",
        "    return gradients\n",
        "\n",
        "def run_deep_dream_with_octaves(img, steps_per_octave=100, step_size=0.01, \n",
        "                                octaves=range(-2,3), octave_scale=1.3):\n",
        "  base_shape = tf.shape(img)\n",
        "  img = tf.keras.utils.img_to_array(img)\n",
        "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "\n",
        "  initial_shape = img.shape[:-1]\n",
        "  #print(\"initial shape\", initial_shape)\n",
        "  img = tf.image.resize(img, initial_shape)\n",
        "  for octave in octaves:\n",
        "    # Scale the image based on the octave\n",
        "    new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n",
        "    new_size = tf.cast(new_size, tf.int32)\n",
        "    img = tf.image.resize(img, new_size)\n",
        "\n",
        "    for step in range(steps_per_octave):\n",
        "      gradients = get_tiled_gradients(img, new_size)\n",
        "      img = img + gradients*step_size\n",
        "      img = tf.clip_by_value(img, -1, 1)\n",
        "\n",
        "      #if step % 10 == 0:\n",
        "        #display.clear_output(wait=True)\n",
        "        #show(deprocess(img))\n",
        "        #print (\"Octave {}, Step {}\".format(octave, step))\n",
        "    \n",
        "  #print(\"final shape\", new_size)\n",
        "  #img = tf.image.resize(img , (1080, 1920))\n",
        "\n",
        "  result = deprocess(img)\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrP2G7lRIsn-",
        "outputId": "40704012-2bbc-467a-d1f8-2f92a81d1242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from torchvision.utils import save_image\n",
        "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
        "\n",
        "# Maximize the activations of these layers\n",
        "names = ['mixed3', 'mixed5','mixed4','mixed8']\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "deepdream = DeepDream(dream_model)\n",
        "\n",
        "for i, img in enumerate(os.listdir(img_path)):\n",
        "  print(i)\n",
        "  original_img = preprocess(os.path.join(img_path, img))\n",
        "  #print(\"1\", original_img.shape)\n",
        "  shift, img_rolled = random_roll(np.array(original_img), 512)\n",
        "  get_tiled_gradients = TiledGradients(dream_model)\n",
        "  img = run_deep_dream_with_octaves(img=original_img, step_size=0.01)\n",
        "  #print(\"2\",img.shape)\n",
        "\n",
        "#  display.clear_output(wait=True)\n",
        "  img = tf.image.resize(img, (1080, 1920))\n",
        "  #print(\"3\", img.shape)\n",
        "  img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
        "  #show(img)\n",
        "  #dream_img = run_deep_dream_simple(img=original_img, steps=100, step_size=0.01)\n",
        "  im = np.array(img)\n",
        "  #print(im.shape)\n",
        "  # plt.imsave(im, f'gdrive/MyDrive/DeepDream/dreamy/frame{i}.png')\n",
        "  im = Image.fromarray(im)\n",
        "  im.save(f'gdrive/MyDrive/DeepDream/dreamy/frame{i}.png')\n",
        "  # plt.imshow(img)\n",
        "  # plt.savefig(f'gdrive/MyDrive/DeepDream/dreamy/frame{i}.png')\n",
        "  #img.save(f'gdrive/MyDrive/DeepDream/dreamy/frame{i}.png')\n",
        "  #save_image(img, f'gdrive/MyDrive/DeepDream/dreamy/frame{i}.png')\n",
        "# original_img = preprocess(timg)\n",
        "# dream_img = run_deep_dream_simple(img=original_img, \n",
        "#                                  steps=300, step_size=0.02)\n",
        "# plt.imshow(dream_img)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JbCnnrhPHoeM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "deepdream.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}